{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b24e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "from spacy.training.example import Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2016a2",
   "metadata": {},
   "source": [
    "### Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "006a6079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluate(data, model):\n",
    "    examples = []\n",
    "    for text, annots in data:\n",
    "        doc = model(text)\n",
    "        examples.append(Example.from_dict(doc, annots))\n",
    "    res = model.evaluate(examples)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e63582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\test\\test_data_json.json', 'r') as f:\n",
    "    test_data_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e28a7b",
   "metadata": {},
   "source": [
    "### Evaluating ner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5f6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from conventional training\n",
    "nlp_ner = spacy.load(r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\models\\model_ner_ef\\model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f0e498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.4558499952166842, 'ents_r': 0.4010605167915159, 'ents_f': 0.4267036804871496, 'ents_per_type': {'B-per': {'p': 0.9048780487804878, 'r': 0.30360065466448444, 'f': 0.45465686274509803}, 'I-per': {'p': 0.6119969627942293, 'r': 0.62, 'f': 0.6159724875811998}, 'B-tim': {'p': 0.6615776081424937, 'r': 0.18544935805991442, 'f': 0.28969359331476324}, 'B-org': {'p': 0.27367205542725176, 'r': 0.16481223922114047, 'f': 0.20572916666666669}, 'B-geo': {'p': 0.4578339991122947, 'r': 0.7512745812090313, 'f': 0.568946497517926}, 'I-org': {'p': 0.3824110671936759, 'r': 0.3073868149324861, 'f': 0.34081902245706736}, 'I-geo': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-gpe': {'p': 0.33007209062821835, 'r': 0.5194489465153971, 'f': 0.40365239294710326}, 'B-eve': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-tim': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-gpe': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-art': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-nat': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-art': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-eve': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-nat': {'p': 0.0, 'r': 0.0, 'f': 0.0}}, 'speed': 5440.945125938445}\n"
     ]
    }
   ],
   "source": [
    "result = Evaluate(test_data_json, nlp_ner)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6445f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from conventional training\n",
    "nlp_ner_trf = spacy.load(r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\models\\model_ner_trf_acc\\model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44c8fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.7268560953253895, 'ents_r': 0.6674522346603822, 'ents_f': 0.6958887280066692, 'ents_per_type': {'B-geo': {'p': 0.6183513990420973, 'r': 0.8932993445010925, 'f': 0.7308207954714733}, 'B-per': {'p': 0.8341511285574092, 'r': 0.6955810147299509, 'f': 0.7585899152164213}, 'I-per': {'p': 0.7091128545564273, 'r': 0.9038461538461539, 'f': 0.7947243828204261}, 'B-tim': {'p': 0.8788617886178862, 'r': 0.7710413694721826, 'f': 0.8214285714285714}, 'B-gpe': {'p': 0.9122807017543859, 'r': 0.6320907617504052, 'f': 0.7467687888942077}, 'B-org': {'p': 0.6935300794551645, 'r': 0.42489568845618914, 'f': 0.5269512721000431}, 'I-geo': {'p': 0.7926829268292683, 'r': 0.20733652312599682, 'f': 0.3286978508217447}, 'I-org': {'p': 0.7471264367816092, 'r': 0.56791104050834, 'f': 0.6453068592057762}, 'B-eve': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-tim': {'p': 0.75, 'r': 0.2777777777777778, 'f': 0.4054054054054055}, 'I-gpe': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-art': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'B-nat': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-art': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-eve': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'I-nat': {'p': 0.0, 'r': 0.0, 'f': 0.0}}, 'speed': 782.0932950060924}\n"
     ]
    }
   ],
   "source": [
    "result = Evaluate(test_data_json, nlp_ner_trf)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dcc056",
   "metadata": {},
   "source": [
    "### Evaluating spancat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e05b9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from spancat training with tranformers\n",
    "nlp_spancat_trf = spacy.load(r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\models\\models_spancat_trf_acc\\model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8686ffb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Evaluate_ner' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14168\\3573463551.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvaluate_ner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlp_spancat_trf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Evaluate_ner' is not defined"
     ]
    }
   ],
   "source": [
    "result = Evaluate_ner(test_data_json, nlp_spancat_trf)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdbe498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

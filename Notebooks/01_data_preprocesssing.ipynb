{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d39294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fcc41fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5f53d",
   "metadata": {},
   "source": [
    "## Loading the groundtruth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "612d0df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 281837: expected 25 fields, saw 34\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word  ...  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of  ...   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators  ...   \n",
       "2       lowercase        marched      VBP  lowercase           have  ...   \n",
       "3       lowercase        through      VBN  lowercase        marched  ...   \n",
       "4     capitalized         London       IN  lowercase        through  ...   \n",
       "\n",
       "  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n",
       "0      __start2__    __START2__        wildcard     __START2__     wildcard   \n",
       "1      __start1__    __START1__        wildcard     __START1__  capitalized   \n",
       "2        thousand           NNS     capitalized      Thousands    lowercase   \n",
       "3              of            IN       lowercase             of    lowercase   \n",
       "4        demonstr           NNS       lowercase  demonstrators    lowercase   \n",
       "\n",
       "       prev-word sentence_idx        shape           word tag  \n",
       "0     __START1__          1.0  capitalized      Thousands   O  \n",
       "1      Thousands          1.0    lowercase             of   O  \n",
       "2             of          1.0    lowercase  demonstrators   O  \n",
       "3  demonstrators          1.0    lowercase           have   O  \n",
       "4           have          1.0    lowercase        marched   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\ner.csv\", encoding='cp1252', on_bad_lines='warn')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f782aeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2549.0     140\n",
       "11994.0    132\n",
       "608.0      124\n",
       "5805.0     122\n",
       "6344.0     120\n",
       "          ... \n",
       "37093.0      2\n",
       "8412.0       2\n",
       "39874.0      2\n",
       "40249.0      2\n",
       "38917.0      1\n",
       "Name: sentence_idx, Length: 35177, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentence_idx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608914e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.sentence_idx.value_counts().index[:10000]\n",
    "#sentences = sentences.index\n",
    "#sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2309b4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860c8429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "0           0  thousand         of        demonstr           NNS   \n",
       "1           1        of   demonstr            have           VBP   \n",
       "2           2  demonstr       have           march           VBN   \n",
       "3           3      have      march         through            IN   \n",
       "4           4     march    through          london           NNP   \n",
       "\n",
       "  next-next-shape next-next-word next-pos next-shape      next-word  ...  \\\n",
       "0       lowercase  demonstrators       IN  lowercase             of  ...   \n",
       "1       lowercase           have      NNS  lowercase  demonstrators  ...   \n",
       "2       lowercase        marched      VBP  lowercase           have  ...   \n",
       "3       lowercase        through      VBN  lowercase        marched  ...   \n",
       "4     capitalized         London       IN  lowercase        through  ...   \n",
       "\n",
       "  prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word   prev-shape  \\\n",
       "0      __start2__    __START2__        wildcard     __START2__     wildcard   \n",
       "1      __start1__    __START1__        wildcard     __START1__  capitalized   \n",
       "2        thousand           NNS     capitalized      Thousands    lowercase   \n",
       "3              of            IN       lowercase             of    lowercase   \n",
       "4        demonstr           NNS       lowercase  demonstrators    lowercase   \n",
       "\n",
       "       prev-word sentence_idx        shape           word tag  \n",
       "0     __START1__          1.0  capitalized      Thousands   O  \n",
       "1      Thousands          1.0    lowercase             of   O  \n",
       "2             of          1.0    lowercase  demonstrators   O  \n",
       "3  demonstrators          1.0    lowercase           have   O  \n",
       "4           have          1.0    lowercase        marched   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = data[data['sentence_idx'].isin(sentences)]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "310aaaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        424516\n",
       "B-geo     17934\n",
       "B-org      9841\n",
       "B-tim      9453\n",
       "I-per      8744\n",
       "I-org      8570\n",
       "B-per      8208\n",
       "B-gpe      8075\n",
       "I-geo      3876\n",
       "I-tim      3057\n",
       "B-art       255\n",
       "B-eve       207\n",
       "I-eve       168\n",
       "I-art       156\n",
       "I-gpe       136\n",
       "B-nat       124\n",
       "I-nat        46\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066452e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parsing data \n",
    "# data_json = []\n",
    "# for i in sentences:\n",
    "#     s = \"\"\n",
    "#     entities = []\n",
    "#     sub_data = new_data[new_data['sentence_idx']==i]\n",
    "#     beg = 0\n",
    "#     for j in sub_data.index:\n",
    "#         word = sub_data.loc[j,'word']\n",
    "#         s = s+' '+word\n",
    "#         tag = sub_data.loc[j,'tag']\n",
    "#         if tag != 'O':\n",
    "#             start = beg+s[beg:].find(word)\n",
    "#             end = start+len(word)\n",
    "#             beg=end\n",
    "#             entities.append([start, end, tag])\n",
    "#     data_json.append([s, {'entities':entities}])\n",
    "# #print(data_json)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a7de7",
   "metadata": {},
   "source": [
    "### Parsing the data to follow this convention:-\n",
    " [\"this is our text\", {'entities':[[start, end, label], [start, end, label]]},</br>\n",
    "\"this is our text\", {'entities':[[start, end, label]]}...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6bade3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing data \n",
    "data_json = []\n",
    "for i in sentences:\n",
    "    s = \"\"\n",
    "    beg = 0\n",
    "    entities = []\n",
    "    sub_data = new_data[new_data['sentence_idx']==i]\n",
    "    for j in sub_data.index:\n",
    "        word = sub_data.loc[j,'word']\n",
    "        s = s+word+' '\n",
    "        start = beg\n",
    "        end = start+len(word)\n",
    "        beg = end+1\n",
    "        tag = sub_data.loc[j,'tag']\n",
    "        if tag != 'O':\n",
    "            entities.append([start, end, tag])\n",
    "    data_json.append([s, {'entities':entities}])\n",
    "#print(data_json)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c84eed70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Annan'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' Last week , Mr. Annan said the U.N. force will have to be bigger and better equipped , which , he said , will require the participation of big and powerful countries with highly trained troops - including the U.S. U.S. officials have said they hope to arrange a U.N. mission to Darfur by the end of this month . Last week , Mr. Annan said the U.N. force will have to be bigger and better equipped , which , he said , will require the participation of big and powerful countries with highly trained troops - including the U.S. U.S. officials have said they hope to arrange a U.N. mission to Darfur by the end of this month .'[17:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e8588a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bcd7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd49e38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 1500, 7000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train dev test split\n",
    "import random\n",
    "test_list = random.sample(range(0, 10000), 1500)\n",
    "test_data_json = [ele for i,ele in enumerate(data_json) if i in test_list]\n",
    "train_data_json = [ele for i,ele in enumerate(data_json) if i not in test_list]\n",
    "dev_list = random.sample(range(0, 8500), 1500)\n",
    "dev_data_json = [ele for i,ele in enumerate(train_data_json) if i in dev_list]\n",
    "train_data_json = [ele for i,ele in enumerate(train_data_json) if i not in dev_list]\n",
    "len(test_data_json), len(dev_data_json), len(train_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9521db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "test_data_json = json.dumps(test_data_json)\n",
    "dev_data_json = json.dumps(dev_data_json)\n",
    "train_data_json = json.dumps(train_data_json)\n",
    "data_json = json.dumps(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3059ebc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in json format\n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\all\\data_json.json', 'w') as f:\n",
    "    f.write(data_json)\n",
    "\n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\train\\train_data_json.json', 'w') as f:\n",
    "    f.write(train_data_json)\n",
    "\n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\dev\\dev_data_json.json', 'w') as f:\n",
    "    f.write(dev_data_json)\n",
    "    \n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\test\\test_data_json.json', 'w') as f:\n",
    "    f.write(test_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb849f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the json back\n",
    "import json\n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\train\\train_data_json.json', 'r') as f:\n",
    "    train_data_json = json.load(f)\n",
    "\n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\dev\\dev_data_json.json', 'r') as f:\n",
    "    dev_data_json = json.load(f)\n",
    "    \n",
    "with open(r'E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train\\test\\test_data_json.json', 'r') as f:\n",
    "    test_data_json = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa8c38",
   "metadata": {},
   "source": [
    "## Function to convert json to spacy format for spacy NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "111ba602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to spacy format of train and dev, save them\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "def json2ner_spacy(ip, dest):\n",
    "    nlp = spacy.blank('en')\n",
    "    db = DocBin()\n",
    "    c = 0\n",
    "    for text, annotation in ip:\n",
    "        c+=1\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotation['entities']:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(dest)\n",
    "    \n",
    "json2ner_spacy(train_data_json, r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_ner\\train\\train.spacy\")\n",
    "json2ner_spacy(dev_data_json, r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_ner\\dev\\dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f36dcc4",
   "metadata": {},
   "source": [
    "## Function to convert spacy ner format to spacy Span Categorizer format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e38490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import typer\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "\n",
    "def ner_spacy2spancat_spacy(src, dest):\n",
    "    \"\"\"\n",
    "    Set the NER data into the doc.spans, under a given key.\n",
    "    The SpanCategorizer component uses the doc.spans, so that it can work with\n",
    "    overlapping or nested annotations, which can't be represented on the\n",
    "    per-token level.\n",
    "    \"\"\"\n",
    "    nlp = spacy.blank('en')\n",
    "    span_key = 'sc'\n",
    "    docbin = DocBin().from_disk(src)\n",
    "    docs = list(docbin.get_docs(nlp.vocab))\n",
    "    for doc in docs:\n",
    "        doc.spans[span_key] = list(doc.ents)\n",
    "    DocBin(docs=docs).to_disk(dest)\n",
    "\n",
    "ner_spacy2spancat_spacy(r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_ner\\train\\train.spacy\", \n",
    "                   r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_spancat\\train\\train.spacy\")\n",
    "ner_spacy2spancat_spacy(r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_ner\\dev\\dev.spacy\", \n",
    "                   r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_spancat\\dev\\dev.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5480776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is a alternate solution to the previous function, here we directly convert json data to spancat spacy data\n",
    "\n",
    "# def json2spancat_spacy(ip, dest):\n",
    "#     \"\"\"\n",
    "#     our json follows ner annotations, we have to \n",
    "#     \"\"\"\n",
    "#     span_key = 'sc'\n",
    "#     nlp = spacy.blank('en')\n",
    "#     db = DocBin()\n",
    "#     c = 0\n",
    "#     for text, annotation in ip:\n",
    "#         c+=1\n",
    "#         doc = nlp(text)\n",
    "#         spans = []\n",
    "#         for start, end, label in annotation['entities']:\n",
    "#             span = doc.char_span(start, end, label=label)\n",
    "#             spans.append(span)\n",
    "#         doc.spans[span_key] = spans\n",
    "#         db.add(doc)\n",
    "#     db.to_disk(dest)\n",
    "    \n",
    "# # json2ner_spacy(train_data_json, r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_spancat\\train\\train.spacy\")\n",
    "# # json2ner_spacy(dev_data_json, r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_spancat\\dev\\dev.spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698148a",
   "metadata": {},
   "source": [
    "# Create classifier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d694b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Hunter agreed , but said : \" If you desire to conquer the Stag , you must permit me to place this piece of iron between your jaws , so that I may guide you with these reins , and allow this saddle to be placed upon your back so that I may keep steady upon you as we follow after the enemy . \" The Hunter agreed , but said : \" If you desire to conquer the Stag , you must permit me to place this piece of iron between your jaws , so that I may guide you with these reins , and allow this saddle to be placed upon your back so that I may keep steady upon you as we follow after the enemy . \" ',\n",
       " {'entities': []}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e4cad5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'B-org', 'I-org', 'B-tim', 'B-art',\n",
       "       'I-art', 'I-per', 'I-geo', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = new_data.tag.unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2519cfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-geo': 0, 'B-gpe': 0, 'B-per': 0, 'B-org': 0, 'I-org': 0, 'B-tim': 0, 'B-art': 0, 'I-art': 0, 'I-per': 0, 'I-geo': 0, 'I-gpe': 0, 'I-tim': 0, 'B-nat': 0, 'B-eve': 0, 'I-eve': 0, 'I-nat': 0}\n"
     ]
    }
   ],
   "source": [
    "cats = {}\n",
    "for k in labels:\n",
    "    cats[k]=0\n",
    "print(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64c0b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['The Hunter agreed , but said : \" If you desire to conquer the Stag , you must permit me to place this piece of iron between your jaws , so that I may guide you with these reins , and allow this saddle to be placed upon your back so that I may keep steady upon you as we follow after the enemy . \" The Hunter agreed , but said : \" If you desire to conquer the Stag , you must permit me to place this piece of iron between your jaws , so that I may guide you with these reins , and allow this saddle to be placed upon your back so that I may keep steady upon you as we follow after the enemy . \" ', {'cats': {'O': 0, 'B-geo': 0, 'B-gpe': 0, 'B-per': 0, 'B-org': 0, 'I-org': 0, 'B-tim': 0, 'B-art': 0, 'I-art': 0, 'I-per': 0, 'I-geo': 0, 'I-gpe': 0, 'I-tim': 0, 'B-nat': 0, 'B-eve': 0, 'I-eve': 0, 'I-nat': 0}}], ['One of them , turning about , said to him : \" That is the very reason why we are so cautious ; for if you yesterday treated us better than the Goats you have had so long , it is plain also that if others came after us , you would in the same manner prefer them to ourselves . \" One of them , turning about , said to him : \" That is the very reason why we are so cautious ; for if you yesterday treated us better than the Goats you have had so long , it is plain also that if others came after us , you would in the same manner prefer them to ourselves . \" ', {'cats': {'O': 0, 'B-geo': 0, 'B-gpe': 0, 'B-per': 0, 'B-org': 0, 'I-org': 0, 'B-tim': 0, 'B-art': 0, 'I-art': 0, 'I-per': 0, 'I-geo': 0, 'I-gpe': 0, 'I-tim': 0, 'B-nat': 0, 'B-eve': 0, 'I-eve': 0, 'I-nat': 0}}]]\n"
     ]
    }
   ],
   "source": [
    "# training data\n",
    "training_textcat_json = []\n",
    "for text, ents in train_data_json:\n",
    "    copy_cat = cats.copy()\n",
    "    available_cats = [i[-1] for i in ents['entities']]\n",
    "    for l in available_cats:\n",
    "        copy_cat[l]=1\n",
    "    data = [text, {'cats':copy_cat}]\n",
    "    training_textcat_json.append(data)\n",
    "\n",
    "print(training_textcat_json[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1640526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"The two most traumatic experiences in the nation 's history were the Civil War ( 1861 - 65 ) , in which a northern Union of states defeated a secessionist Confederacy of 11 southern slave states , and the Great Depression of the 1930s , an economic downturn during which about a quarter of the labor force lost its jobs . The two most traumatic experiences in the nation 's history were the Civil War ( 1861 - 65 ) , in which a northern Union of states defeated a secessionist Confederacy of 11 southern slave states , and the Great Depression of the 1930s , an economic downturn during which about a quarter of the labor force lost its jobs . \", {'cats': {'O': 0, 'B-geo': 1, 'B-gpe': 0, 'B-per': 0, 'B-org': 1, 'I-org': 1, 'B-tim': 1, 'B-art': 0, 'I-art': 0, 'I-per': 0, 'I-geo': 0, 'I-gpe': 0, 'I-tim': 0, 'B-nat': 0, 'B-eve': 0, 'I-eve': 0, 'I-nat': 0}}]]\n"
     ]
    }
   ],
   "source": [
    "print(training_textcat_json[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8df9bdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_textcat_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb91603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "nlp = spacy.blank('en')\n",
    "db = DocBin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "00e4d933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-geo', 'B-gpe', 'B-per', 'B-org', 'I-org', 'B-tim', 'B-art',\n",
       "       'I-art', 'I-per', 'I-geo', 'I-gpe', 'I-tim', 'B-nat', 'B-eve',\n",
       "       'I-eve', 'I-nat'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c4ad41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text, annots in training_textcat_json[:100]:\n",
    "    doc = nlp(text)\n",
    "    doc.cats = annots['cats']\n",
    "    db.add(doc)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1363a84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 1,\n",
       " 'B-per': 1,\n",
       " 'B-org': 1,\n",
       " 'I-org': 1,\n",
       " 'B-tim': 0,\n",
       " 'B-art': 0,\n",
       " 'I-art': 0,\n",
       " 'I-per': 1,\n",
       " 'I-geo': 0,\n",
       " 'I-gpe': 0,\n",
       " 'I-tim': 0,\n",
       " 'B-nat': 0,\n",
       " 'B-eve': 0,\n",
       " 'I-eve': 0,\n",
       " 'I-nat': 0}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af03e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_disk(r\"E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_textcat\\train\\train.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bd427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to spacy format of train and dev, save them\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "def json2textcat_spacy(ip, dest):\n",
    "    nlp = spacy.blank('en')\n",
    "    db = DocBin()\n",
    "    c = 0\n",
    "    for text, annotation in ip:\n",
    "        c+=1\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotation['entities']:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b3748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

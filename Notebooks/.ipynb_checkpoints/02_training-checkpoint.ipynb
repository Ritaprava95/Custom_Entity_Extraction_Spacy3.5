{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ed226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create traing config\n",
    "# initialize config file \n",
    "# !python -m spacy init config --lang en --pipeline spancat E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs_spancat\\config_spancat_trf_acc.cfg --force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae090d",
   "metadata": {},
   "source": [
    "# Approaching as spacy NER problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860148f7",
   "metadata": {},
   "source": [
    "## NER with conventional backend\n",
    "#### config_ner_ef is made for ner and efficiency with conventinal spacy backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67840c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m[+] Saved config\u001b[0m\n",
      "E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_1.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_1.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# auto fill the config_ner_ef file\n",
    "!python -m spacy init fill-config E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_ner_ef.cfg E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_ner_ef.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25f3ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m[i] Saving to output directory:\n",
      "E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\models\\model_ner_ef\u001b[0m\n",
      "\u001b[38;5;4m[i] Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m[+] Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m[i] Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4m[i] Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     54.50    5.33    3.32   13.57    0.05\n",
      "  0      10          0.80    459.42    0.00    0.00    0.00    0.00\n",
      "  0      20          1.15    225.16    8.47   43.02    4.70    0.08\n",
      "  0      30          0.80    228.88   18.43   36.22   12.36    0.18\n",
      "  0      40          0.44    146.27   32.34   33.50   31.26    0.32\n",
      "  0      50          0.72    135.99   36.54   39.00   34.38    0.37\n",
      "  0      60          0.98    158.28   27.17   26.37   28.03    0.27\n",
      "  0      70          0.66    125.73   29.73   34.99   25.84    0.30\n",
      "  0      80          0.62    116.30   37.95   42.46   34.30    0.38\n",
      "  0      90          0.71    125.38   43.83   46.65   41.34    0.44\n",
      "  0     100          0.74    128.67   43.27   43.12   43.43    0.43\n",
      "\u001b[38;5;2m[+] Saved pipeline to output directory\u001b[0m\n",
      "E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\models\\model_ner_ef\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-07 12:18:55,031] [INFO] Set up nlp object from config\n",
      "[2023-03-07 12:18:55,047] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-03-07 12:18:55,051] [INFO] Created vocabulary\n",
      "[2023-03-07 12:18:55,053] [INFO] Finished initializing nlp object\n",
      "[2023-03-07 12:19:03,462] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# train spacy\n",
    "!python -m spacy train E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_ner_ef.cfg --output E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\models\\model_ner_ef\\ --paths.train E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\data\\Train_ner\\train\\train.spacy --paths.dev E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\data\\Train_ner\\dev\\dev.spacy --training.eval_frequency 10 --training.max_steps 100 --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a74f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy debug config E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_1.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9b7f1",
   "metadata": {},
   "source": [
    "## NER with transformer\n",
    "#### config_ner_trf_acc is made for ner and accuracy with transformer backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86759a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m[+] Saved config\u001b[0m\n",
      "E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_2.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_2.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# auto fill the config_2 file\n",
    "!python -m spacy init fill-config E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_ner_trf_acc.cfg E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_ner_trf_acc.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0858bbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m[i] Saving to output directory:\n",
      "E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\models\\model_ner_trf_acc\u001b[0m\n",
      "\u001b[38;5;4m[i] Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m[+] Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4m[i] Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4m[i] Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "  0       0          88.77    191.70    0.06    0.28    0.03    0.00\n",
      "  0      10        9449.07  16287.68    0.00    0.00    0.00    0.00\n",
      "  0      20        6015.67  12512.76    0.00    0.00    0.00    0.00\n",
      "  0      30        4921.33  10464.82    0.00    0.00    0.00    0.00\n",
      "  0      40        2282.44   4740.72    0.00    0.00    0.00    0.00\n",
      "  0      50        1829.62   3676.05    0.00    0.00    0.00    0.00\n",
      "  0      60        1522.88   3002.58    0.00    0.00    0.00    0.00\n",
      "  0      70        1469.58   2842.80   33.27   40.13   28.42    0.33\n",
      "  0      80        1214.33   2333.63   54.09   54.00   54.17    0.54\n",
      "  0      90        1018.89   1980.47   61.36   63.68   59.20    0.61\n",
      "  0     100         830.86   1606.56   69.56   72.37   66.95    0.70\n",
      "\u001b[38;5;2m[+] Saved pipeline to output directory\u001b[0m\n",
      "E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\models\\model_ner_trf_acc\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-03-07 13:10:12,075] [INFO] Set up nlp object from config\n",
      "[2023-03-07 13:10:12,092] [INFO] Pipeline: ['transformer', 'ner']\n",
      "[2023-03-07 13:10:12,096] [INFO] Created vocabulary\n",
      "[2023-03-07 13:10:12,098] [INFO] Finished initializing nlp object\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[2023-03-07 13:10:28,593] [INFO] Initialized pipeline components: ['transformer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "# train spacy\n",
    "!python -m spacy train E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_ner_trf_acc.cfg --output E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\models\\model_ner_trf_acc\\ --paths.train E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\data\\Train_ner\\train\\train.spacy --paths.dev E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\data\\Train_ner\\dev\\dev.spacy --training.eval_frequency 10 --training.max_steps 100 --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bac9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy debug config E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_2.cfg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146fb77",
   "metadata": {},
   "source": [
    "# Approaching as Span Categorizer problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f48bed",
   "metadata": {},
   "source": [
    "## SpanCat with transformer\n",
    "#### config_spancat_trf_acc is made for span categorization and accuracy with transformer backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1376a5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m[+] Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m[+] Saved config\u001b[0m\n",
      "E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs_spancat\\config_spancat_trf_acc.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config_spancat_trf_acc.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# auto fill the config_2 file\n",
    "!python -m spacy init fill-config E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_spancat_trf_acc.cfg E:\\Work\\Data_Science\\Projects\\Custom_NER_Spacy3.5\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_spancat_trf_acc.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f2a8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.7 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: python -m spacy train [OPTIONS] CONFIG_PATH\n",
      "Try 'python -m spacy train --help' for help.\n",
      "\n",
      "Error: Invalid value for 'CONFIG_PATH': Path 'E:\\\\Work\\\\Data_Science\\\\Projects\\\\Custom_NER_Spacy3.5\\\\Custom_Entity_Extraction_Spacy3.5\\\\configs\\\\config_spancat_trf_acc.cfg' does not exist.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train spacy\n",
    "!python -m spacy train E:\\Work\\Data_Science\\Projects\\Custom_NER\\Custom_Entity_Extraction_Spacy3.5\\configs\\config_spancat_trf_acc.cfg --output E:\\Work\\Data_Science\\Projects\\Custom_NER\\models\\models_spancat_trf_acc\\ --paths.train E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_spancat\\train\\train.spacy --paths.dev E:\\Work\\Data_Science\\Projects\\Custom_NER\\data\\Train_spancat\\dev\\dev.spacy --training.eval_frequency 10 --training.max_steps 100 --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44a95b",
   "metadata": {},
   "source": [
    "#### N.B. Due to lack of hardware resource the training could not be completed for all 100 epochs, instead it could only go pass 50 epochs and saved the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d430e668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30328c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbeced12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x20ea5511ba0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load(\"en_core_web_trf\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4367033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52238f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
